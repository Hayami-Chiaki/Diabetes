{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c02dd9b8",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67ab9a-4f6c-4bf7-bacf-07e53676e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data=pd.read_csv(\"./data.csv\")\n",
    "y=data['target']\n",
    "scaler=StandardScaler()   #标准化\n",
    "x=data.drop(columns=['id', 'target'])\n",
    "x=scaler.fit_transform(x)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "knn=KNN()\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dc759",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeec957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "# X = data.iloc[:, :-1]\n",
    "# y = data.iloc[:, -1]\n",
    "\n",
    "# 划分训练集和测试集\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "Diabetes_data = data.iloc[0:10000, 1:22]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Diabetes_data, data.target.iloc[0:10000], random_state=78, test_size=0.2\n",
    ")\n",
    "\n",
    "\n",
    "# 标准化特征值\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 创建SVM模型\n",
    "svm_model = SVC(kernel='rbf')\n",
    "\n",
    "# 训练模型\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"准确率: {accuracy}\")\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred,average=\"macro\")\n",
    "\n",
    "print(f1)\n",
    "\n",
    "# 计算并绘制混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=svm_model.classes_, columns=svm_model.classes_)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predict')\n",
    "plt.ylabel('Actually')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606fc9e",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "Diabetes = pd.read_csv(\"./data.csv\")\n",
    "\n",
    "Diabetes_data = Diabetes.iloc[:, 1:22]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    Diabetes_data, Diabetes.target, random_state=78, test_size=0.2\n",
    ")\n",
    "\n",
    "params_classifier = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_leaves\": 19,\n",
    "    \"learning_rate\": 0.3,\n",
    "    \"lambda_l1\":0.3,\n",
    "    \"lambda_l2\":0.1,\n",
    "    \"n_estimators\":1000,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.6,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"verbose\": -1,\n",
    "    \"num_class\": 3,\n",
    "}\n",
    "\n",
    "model_classifier = lgb.LGBMClassifier(**params_classifier)\n",
    "\n",
    "model_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_classifier = model_classifier.predict(x_test)\n",
    "\n",
    "f1_classifier = f1_score(y_test, y_pred_classifier,average=\"macro\")\n",
    "\n",
    "print(\"f1_score:\",f1_classifier)\n",
    "\n",
    "print(\"分类报告:\")\n",
    "print(classification_report(y_test, y_pred_classifier, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a4f33",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#数据集的获取\n",
    "diabetes=pd.read_csv(\"./data.csv\")\n",
    "features=['HighBP','HighChol','CholCheck','BMI','Smoker','Stroke','HeartDiseaseorAttack','PhysActivity','Fruits','HvyAlcoholConsump','AnyHealthcare','NoDocbcCost','GenHlth','MentHlth','PhysHlth','DiffWalk','Sex','Age','Education','Income']\n",
    "\n",
    "#数据集的划分\n",
    "x_train,x_test,y_train,y_test=train_test_split(diabetes[features],diabetes['target'],random_state=100,test_size=0.3)\n",
    "\n",
    "#特征工程\n",
    "transfer=StandardScaler()\n",
    "x_train=transfer.fit_transform(x_train)\n",
    "x_test=transfer.fit_transform(x_test)\n",
    "\n",
    "#设置xgboost的参数\n",
    "params={'learning_rate':0.3,\n",
    "        'max_depth':3,\n",
    "        'objective':'multi:softmax',\n",
    "        'eval_metric':'mlogloss',\n",
    "        'num_class':3\n",
    "}\n",
    "\n",
    "#将测试集、训练集转化为DMatrix格式\n",
    "dtrain=xgb.DMatrix(x_train,label=y_train)\n",
    "dtest=xgb.DMatrix(x_test,label=y_test)\n",
    "\n",
    "#机器学习\n",
    "model=xgb.train(params,dtrain,num_boost_round=100,evals=[(dtest,'mlogloss')],early_stopping_rounds=10)\n",
    "\n",
    "#模型评估\n",
    "y_pred=model.predict(dtest)\n",
    "print(y_pred)\n",
    "f1_score=f1_score(y_test,y_pred,average='macro')\n",
    "print('f1_score =',f1_score)\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print('accuracy_score =',accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b75ed",
   "metadata": {},
   "source": [
    "决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2042ac61",
   "metadata": {},
   "source": [
    "GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "data = pd.read_csv('./data.csv')\n",
    "x = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "frac_to_use = 0.06\n",
    "indices = np.random.choice(x.index, size=int(frac_to_use * len(x)), replace=False)\n",
    "x_small = x.loc[indices]\n",
    "y_small = y.loc[indices]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_small, y_small, test_size=0.2, random_state=142, stratify=y_small)\n",
    "\n",
    "def optuna_objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 50)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        subsample=subsample,\n",
    "        random_state=142\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=142)\n",
    "    cv_scores = cross_val_score(gbc, x_train, y_train, cv=kf, scoring=make_scorer(f1_score, average='macro'))\n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    return mean_cv_score\n",
    "def optimizer_optuna(n_trials):\n",
    "    study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(optuna_objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    print(study.best_trial.params, study.best_trial.value)\n",
    "    return study.best_trial.params, study.best_trial.value\n",
    "best_params, best_score = optimizer_optuna(25)\n",
    "best_model = GradientBoostingClassifier(**best_params, random_state=142)\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nAccuracy:\")\n",
    "print(accuracy)\n",
    "print(\"\\nF1 Score (macro):\")\n",
    "print(f1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00609dda",
   "metadata": {},
   "source": [
    "DecisionTree_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66348212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "x = data.drop('target', axis=1) \n",
    "y = data['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"F1-Score : {f1}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0407eae3",
   "metadata": {},
   "source": [
    "DecisionTree_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "from scipy.stats import randint\n",
    "data = pd.read_csv(\"./data.csv\")\n",
    "x = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,stratify=y)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "param_dist = {\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 100),\n",
    "    'min_samples_leaf': randint(1, 100),\n",
    "    'criterion': ['gini', 'entropy']  \n",
    "}\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(x_train, y_train)\n",
    "best_clf = random_search.best_estimator_\n",
    "y_pred = best_clf.predict(x_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro') \n",
    "print(f\"F1-Score : {f1}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
